{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 数据操作"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 张量表示一个数值组成的数组，这个数组可能有多个维度"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12)\n",
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 我们可以通过张量的shape属性来访问张量的形状和张量中元素的总数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([12])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "12"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 要改变一个张量的形状而不改变元素数量和元素值，我们可以调用reshape函数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11]])"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = x.reshape(3, 4)\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 使用全0，全1，其他常量或者特定分布中随机采样的数字\n",
    "##### zeros((H,W,L)) ,L表示长度（行数），W表示宽度（深度），H表示高度（列数）"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0., 0., 0., 0.],\n         [0., 0., 0., 0.],\n         [0., 0., 0., 0.]],\n\n        [[0., 0., 0., 0.],\n         [0., 0., 0., 0.],\n         [0., 0., 0., 0.]]])"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((2,3,4)) ## 表示2行3纵4列"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]]])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((2,3,4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.4702, -0.7481, -0.5994,  0.3374],\n        [ 1.0276, -0.1551, -0.9852, -0.1793],\n        [-1.3049, -0.0147,  0.1721,  0.6641]])"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3,4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 也可以通过提供包含数值的Python列表（或嵌套列表）来为所需张量中的每个元素赋予确定值"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2, 1, 4, 3],\n        [1, 2, 3, 4],\n        [4, 3, 2, 1]])"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[2,1,4,3],[1,2,3,4],[4,3,2,1]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 常见的标准算术运算符（+，-，*，/和**）都可以被升级为按元素运算"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([5, 5, 5, 5]),\n tensor([-3, -1,  1,  3]),\n tensor([4, 6, 6, 4]),\n tensor([0.2500, 0.6667, 1.5000, 4.0000]),\n tensor([1, 8, 9, 4]))"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3,4])\n",
    "y = torch.tensor([4,3,2,1])\n",
    "x+y, x-y, x*y, x/y, x**y # **运算符是求幂运算"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 2.7183,  7.3891, 20.0855, 54.5981])"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 我们也可以把多个张量连结在一起\n",
    "##### dim=0时，是按行进行连接的，dim=1时是按列进行连接的，默认是按行进行连接的"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[ 0.,  1.,  2.,  3.]],\n \n         [[ 4.,  5.,  6.,  7.]],\n \n         [[ 8.,  9., 10., 11.]]]),\n tensor([[[2., 1., 4., 3.]],\n \n         [[1., 2., 3., 4.]],\n \n         [[4., 3., 2., 1.]]]),\n tensor([[[-1.1868,  1.8158, -1.1139,  0.4395]],\n \n         [[ 1.6352,  0.8161,  0.8873, -1.3573]],\n \n         [[ 3.4009, -1.2380, -0.5669, -1.7974]]]))"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(12, dtype = torch.float32).reshape((3,1,4))\n",
    "Y = torch.tensor([[[2.0, 1, 4, 3]], [[1, 2, 3, 4]], [[4, 3, 2, 1]]])\n",
    "Z = torch.randn((3,1,4))\n",
    "X, Y, Z\n",
    "# torch.cat((X,Y,Z),dim=0), torch.cat((X,Y,Z),dim=1) ,torch.cat((X,Y,Z),dim=2)## dim=0时，是按行进行连接的，dim=1时是按列进行连接的，默认是按行进行连接的"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([9, 1, 4]),\n torch.Size([3, 3, 4]),\n torch.Size([3, 1, 12]),\n torch.Size([6, 1, 4]))"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((X,Y,Z),dim=0).shape, torch.cat((X,Y,Z),dim=1).shape,torch.cat((X,Y,Z),dim=2).shape,torch.cat((X,Y)).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 可以通过逻辑运算符构建二元张量\n",
    "##### 对张量中的所有元素求和会产生一个只有一个元素的张量"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[False,  True, False,  True]],\n \n         [[False, False, False, False]],\n \n         [[False, False, False, False]]]),\n tensor(66.),\n tensor([[[ 0.,  2.,  4.,  6.]],\n \n         [[ 8., 10., 12., 14.]],\n \n         [[16., 18., 20., 22.]]]))"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X == Y, X.sum(),X.mul(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 即使形状不同，仍然可以通过调用广播机制（broadcasting mechanism）来执行按元素操作\n",
    "##### 以下示例中的两个张量分别是$（3*1）$和$（1*2）$，原则上不可以进行相加的操作的，但是广播机制会将a和b都扩充成（3*2）的格式，其中a相当于将列数复制一份给第2列，b相当于将行数复制一份给第2行\n",
    "## <font color='red'>广播机制的连个参数中必须要有一个行数或者列数为1才可以，因为它无法进行超过一行或者一列的复制 </font>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[0],\n         [1],\n         [2]]),\n tensor([[0, 1]]),\n tensor([[0, 1],\n         [1, 2],\n         [2, 3]]))"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(3).reshape((3,1))\n",
    "b = torch.arange(2).reshape((1,2))\n",
    "a,b,a+b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 可以使用[-1]来获取最后一个的元素，可以使用[1:3]来获取第二个和第三个元素"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[ 8.,  9., 10., 11.]]),\n tensor([[[ 4.,  5.,  6.,  7.]],\n \n         [[ 8.,  9., 10., 11.]]]))"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[-1],X[1:3] ## 这里显示的是X的倒数第一行，以及X的第2行和第3行的元素"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 除了读取以外，还可以通过指定索引将元素写入张量或者矩阵中,可以指定某一行或某一列进行批量操作"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0., 1., 2., 3.]],\n\n        [[4., 9., 6., 7.]],\n\n        [[8., 8., 8., 8.]]])"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1,0,1] = 9\n",
    "X[2] = 8\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 运行一些操作时可能会导致会为新的结果分配新的内存\n",
    "##### 以下示例在执行Y = Y+X后为Y分配了新的内存空间，所以前后两次的内存空间id不一致"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(Y)\n",
    "Y = X + Y\n",
    "id(Y) == before"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 上述的重新分配空间的问题，为节省空间可以执行一些原地操作，原地操作不会为参数分配新的内存空间\n",
    "##### 原地操作有两种:\n",
    "> * X[ : ] = X + Y\n",
    "> * X += Y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(Z): 3112597298528\n",
      "id(Z): 3112597298528\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "Z = torch.zeros_like(Y)\n",
    "print('id(Z):', id(Z))\n",
    "Z[:] = X + Y\n",
    "print('id(Z):', id(Z))\n",
    "before = id(Y)\n",
    "Y += X\n",
    "print(id(Y) == before)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 可以通过一些操作实现张量和Numpy之间的转换"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "(numpy.ndarray, torch.Tensor)"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = X.numpy()\n",
    "B = torch.tensor(A)\n",
    "type(A), type(B)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 大小为1的张量可以转换为python的标量\n",
    "> * 这其中就可使用x.item()进行转换\n",
    "> * 也可以使用float(x),int(x)这种方式进行强制转换"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([3.5000]), 3.5, float, 3.5, 3)"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([3.5])\n",
    "a, a.item(),type(a.item()),float(a),int(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### m, n = (x[:, 2:] > numbwe).nonzore(as_tuple = False) ,number为某个数值\n",
    "##### 这行代码输出的m是从第3列后所有大于number的行数下标，n代表所有的列数下标，但是列将会从第3列进行重新从0开始计数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3]),\n tensor([1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2]))"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(20, dtype = torch.float32).reshape((4,5))\n",
    "m , n = (x[:, 2:] > 2).nonzero(as_tuple=False).T\n",
    "m , n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 3.],\n        [ 4.],\n        [ 7.],\n        [ 8.],\n        [ 9.],\n        [12.],\n        [13.],\n        [14.],\n        [17.],\n        [18.],\n        [19.]])"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[m, n+2, None]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### o,p = X[:,2:].max(1,keepdim=True)中o输出从第3列开始之后的最大值，p表示存储该最大值的列数下标，但是存储的列是从第3三列重新开始从0进行计数的"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[ 4.],\n         [ 9.],\n         [14.],\n         [19.]]),\n tensor([[2],\n         [2],\n         [2],\n         [2]]))"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o,p = x[:,2:].max(1,keepdim=True)\n",
    "o,p"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "M = torch.arange(72, dtype=torch.float32).reshape((3,4,6))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[ 0.,  2.,  4.],\n          [12., 14., 16.]],\n \n         [[24., 26., 28.],\n          [36., 38., 40.]],\n \n         [[48., 50., 52.],\n          [60., 62., 64.]]]),\n tensor([[[ 6.,  8., 10.],\n          [18., 20., 22.]],\n \n         [[30., 32., 34.],\n          [42., 44., 46.]],\n \n         [[54., 56., 58.],\n          [66., 68., 70.]]]),\n tensor([[[ 1.,  3.,  5.],\n          [13., 15., 17.]],\n \n         [[25., 27., 29.],\n          [37., 39., 41.]],\n \n         [[49., 51., 53.],\n          [61., 63., 65.]]]),\n tensor([[[ 7.,  9., 11.],\n          [19., 21., 23.]],\n \n         [[31., 33., 35.],\n          [43., 45., 47.]],\n \n         [[55., 57., 59.],\n          [67., 69., 71.]]]))"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M[..., ::2, ::2], M[..., 1::2, ::2], M[..., ::2, 1::2], M[..., 1::2, 1::2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 0.,  2.,  4.],\n         [12., 14., 16.],\n         [ 6.,  8., 10.],\n         [18., 20., 22.],\n         [ 1.,  3.,  5.],\n         [13., 15., 17.],\n         [ 7.,  9., 11.],\n         [19., 21., 23.]],\n\n        [[24., 26., 28.],\n         [36., 38., 40.],\n         [30., 32., 34.],\n         [42., 44., 46.],\n         [25., 27., 29.],\n         [37., 39., 41.],\n         [31., 33., 35.],\n         [43., 45., 47.]],\n\n        [[48., 50., 52.],\n         [60., 62., 64.],\n         [54., 56., 58.],\n         [66., 68., 70.],\n         [49., 51., 53.],\n         [61., 63., 65.],\n         [55., 57., 59.],\n         [67., 69., 71.]]])"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([M[..., ::2, ::2], M[..., 1::2, ::2], M[..., ::2, 1::2], M[..., 1::2, 1::2]],1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.5 , 0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95])"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "IouTh = np.linspace(\n",
    "            0.5, 0.95, int(np.round((0.95 - 0.5) / 0.05)) + 1, endpoint=True\n",
    "        )\n",
    "IouTh"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\house_tiny.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
    "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
    "print(data_file)\n",
    "with open(data_file, 'w')as f:\n",
    "    f.write('NumRooms,Alley,Price\\n')\n",
    "    f.write('NA,Pave,127500\\n')\n",
    "    f.write('2,NA,106000\\n')\n",
    "    f.write('4,NA,178100\\n')\n",
    "    f.write('NA,NA,140000\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley   Price\n",
      "0       NaN  Pave  127500\n",
      "1       2.0   NaN  106000\n",
      "2       4.0   NaN  178100\n",
      "3       NaN   NaN  140000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(data_file)\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "为了处理缺失的数据，典型的方法包括<font color='red'>插值</font>和<font color='red'>删除</font>，以下，考虑插值"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "   NumRooms Alley\n0       3.0  Pave\n1       2.0   NaN\n2       4.0   NaN\n3       3.0   NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NumRooms</th>\n      <th>Alley</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.0</td>\n      <td>Pave</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, outputs = data.iloc[:,0:2], data.iloc[:,2]## 取值操作\n",
    "inputs = inputs.fillna(inputs.mean(numeric_only=True)) ## numeric_only表示仅选择对函数有效的列，fillna表示使用某个值填充所有的空值\n",
    "inputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "对于inputs中的类别值和离散值，将‘NaN’视为一个类别"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "   NumRooms  Alley_Pave  Alley_nan\n0       3.0           1          0\n1       2.0           0          1\n2       4.0           0          1\n3       3.0           0          1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NumRooms</th>\n      <th>Alley_Pave</th>\n      <th>Alley_nan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs =pd.get_dummies(inputs,dummy_na=True)\n",
    "inputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[3., 1., 0.],\n         [2., 0., 1.],\n         [4., 0., 1.],\n         [3., 0., 1.]], dtype=torch.float64),\n tensor([127500, 106000, 178100, 140000]))"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y = torch.tensor(inputs.values),torch.tensor(outputs.values)\n",
    "X,y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(12)\n",
    "b =  a.reshape((3,4))\n",
    "b[:] = 2\n",
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.view(3,4)\n",
    "c[:] = 1\n",
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}