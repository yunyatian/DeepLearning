{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyNx3V4a30SpjSoicYhXYji7"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard",
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8c2h4eNBn6FT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679042260262,
     "user_tz": -480,
     "elapsed": 854,
     "user": {
      "displayName": "yatian yun",
      "userId": "14499165712729714688"
     }
    },
    "outputId": "deb5b4a5-7a1d-4f7c-bf37-c698a13412b6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fri Mar 17 08:37:38 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   58C    P0    28W /  70W |    573MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "torch.device('cpu'), torch.cuda.device('cuda'), torch.cuda.device('cuda:1')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7_Lq2GOGoE_1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679042260263,
     "user_tz": -480,
     "elapsed": 15,
     "user": {
      "displayName": "yatian yun",
      "userId": "14499165712729714688"
     }
    },
    "outputId": "bb0ccef9-cb98-408e-ab61-6698c7f87353",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(device(type='cpu'),\n",
       " <torch.cuda.device at 0x7f90936789d0>,\n",
       " <torch.cuda.device at 0x7f9093678220>)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.cuda.device_count()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p1ZGtNlJpAya",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679042260263,
     "user_tz": -480,
     "elapsed": 13,
     "user": {
      "displayName": "yatian yun",
      "userId": "14499165712729714688"
     }
    },
    "outputId": "bba2d250-2073-4f24-f646-9718e8469b56",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"以下两个函数保证了当请求GPU不存在的情况下仍然可以运行代码\"\"\"\n",
    "def try_gpu(i=0):\n",
    "  \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n",
    "  if torch.cuda.device_count() >= i+1:\n",
    "    return torch.device(f'cuda:{i}')\n",
    "  return torch.device('cpu')\n",
    "\n",
    "def try_all_gpus():\n",
    "  \"\"\"返回所有可用gpu，如果没有GPU， 返回[cpu(),]\"\"\"\n",
    "  devices = [torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
    "  return devices if devices else [torch.device('cpu')]\n",
    "\n",
    "try_gpu(), try_gpu(10), try_all_gpus()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hIoxDg4ypFoJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679042260264,
     "user_tz": -480,
     "elapsed": 13,
     "user": {
      "displayName": "yatian yun",
      "userId": "14499165712729714688"
     }
    },
    "outputId": "3471eba0-b986-4f40-e135-6ec7ffef95cd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(device(type='cuda', index=0),\n",
       " device(type='cpu'),\n",
       " [device(type='cuda', index=0)])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"查询张量所在设备\"\"\"\n",
    "x = torch.tensor([1, 2, 3])\n",
    "x.device"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UQAVOBCvqsxF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679042260264,
     "user_tz": -480,
     "elapsed": 12,
     "user": {
      "displayName": "yatian yun",
      "userId": "14499165712729714688"
     }
    },
    "outputId": "97d5dc6f-fa90-45d5-a62a-f7a00ca1c9f5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"存储在GPU上\"\"\"\n",
    "X = torch.ones(2, 3, device=try_gpu())\n",
    "X"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3eDNedDqroUn",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679042260264,
     "user_tz": -480,
     "elapsed": 11,
     "user": {
      "displayName": "yatian yun",
      "userId": "14499165712729714688"
     }
    },
    "outputId": "e50d700e-795a-40a6-9a96-b89571b799bc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"在第二个GPU上创建一个随机张量\"\"\"\n",
    "Y = torch.rand(2, 3, device=try_gpu(0))\n",
    "Y"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oJFku2DOr5lH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679042260264,
     "user_tz": -480,
     "elapsed": 10,
     "user": {
      "displayName": "yatian yun",
      "userId": "14499165712729714688"
     }
    },
    "outputId": "9624291d-b084-4a83-fa50-4fae77322c47",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.2220, 0.5823, 0.6948],\n",
       "        [0.8425, 0.8729, 0.8235]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "Z = X.cuda(0)\n",
    "print(X)\n",
    "print(Z)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2QbnJf40sPI4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679042260264,
     "user_tz": -480,
     "elapsed": 9,
     "user": {
      "displayName": "yatian yun",
      "userId": "14499165712729714688"
     }
    },
    "outputId": "d7709642-c78b-477b-a8da-1278d99eb550",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0')\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0')\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "Y + Z"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kfzq1_CVszp7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679042260265,
     "user_tz": -480,
     "elapsed": 9,
     "user": {
      "displayName": "yatian yun",
      "userId": "14499165712729714688"
     }
    },
    "outputId": "26b6a6ee-8755-484e-e687-dfbf60928326",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1.2220, 1.5823, 1.6948],\n",
       "        [1.8425, 1.8729, 1.8235]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "Z.cuda(0) is Z"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cm4hSXYls28M",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679042260265,
     "user_tz": -480,
     "elapsed": 8,
     "user": {
      "displayName": "yatian yun",
      "userId": "14499165712729714688"
     }
    },
    "outputId": "e5946f22-a052-424d-b865-e4d8e5f2f0c6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "net = nn.Sequential(nn.Linear(3, 1))\n",
    "net = net.to(device = try_gpu())\n",
    "\n",
    "net(X)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d84Ew2cdtIg5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679042262568,
     "user_tz": -480,
     "elapsed": 2310,
     "user": {
      "displayName": "yatian yun",
      "userId": "14499165712729714688"
     }
    },
    "outputId": "11840150-06ea-47fb-f847-266bd5ffdc72",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.8331],\n",
       "        [-0.8331]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "net[0].weight.data.device"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nVnuGm0wtVBb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679042262569,
     "user_tz": -480,
     "elapsed": 6,
     "user": {
      "displayName": "yatian yun",
      "userId": "14499165712729714688"
     }
    },
    "outputId": "49fbfb85-f17a-4e32-9682-55d4891ad434",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ]
  }
 ]
}